---
layout: post
title: "目标检测相关知识点总结"
subtitle: "目标检测"
author: WenlSun"
header-style: text
tag:
  - 计算机视觉
  - 深度学习
---
**目标检测任务**：是找出图像中所有感兴趣的而目标(物体)，确定他们的位置和大小，是机器视觉领域的核心问题之一。

## 目标检测算法的工作流程

### 两阶段方法

两阶段目标检测算法以R-CNN系列为代表的一系列方法。它们的工作流程是，给定一幅图像，首先从图像中获取候选框，然后对候选框进行分类和位置修正。

### 单阶段方法

单阶段目标检测算法以YOLO和SDD为代表。

### Anchor Free方法

Anchor Free目标检测算法以FCOS，CenterNet为代表。

## RPN的原理

RPN第一次出现在世人眼中是在Faster RCNN这个结构中，专门用来提取候选框，在RCNN和Fast RCNN等物体检测架构中，用来提取候选框的方法通常是`Selective Search`，是比较传统的方法，而且**比较耗时**，在CPU上要2s一张图。所以作者提出RPN，专门用来提取候选框，一方面RPN耗时少，另一方面RPN可以很容易结合到Fast RCNN中，称为一个整体。RPN的引入，可以说是真正意义上把物体检测整个流程融入到一个神经网络中。

![1589170713059](/img/目标检测知识点总结/RPN.png)

### RPN 运作机制
首先通过一系列卷积得到公共特征图，假设他的大小是$N \times 16 \times 16$，然后我们进入RPN阶段，首先经过一个$3 \times 3$的卷积，得到一个$256 \times 16 \times 16$的特征图，也可以看作$16 \times 16$个256维特征向量，然后经过两次$1 \times 1$的卷积，分别得到一个$18 \times 16 \times 16$的特征图，和一个$36 \times 16 \times 16$的特征图，也就是$16 \times 16 \times 9$个结果，每个结果包含2个分数和4个坐标，再结合预先定义的Anchors，经过后处理，就得到候选框。

![1589170523865](/img/目标检测知识点总结/RPN2.png)

## RoIPooling、RoIAlign和RRoIPooling

### RoIPooling

### RPNAlign

### RRoIPooling

## IoU计算

### 水平框IoU计算

直接看代码！！！

#### 参考代码(Python 版本)

``` python
areas1 = (x2[0]-x1[0]+1)*(y2[0]-y1[0]+1)
areas2 = (x2[1]-x1[1]+1)*(y2[1]-y1[1]+1)
# x1[0] 表示第一个矩形的左上点的横坐标
# x1[1] 表示第二个矩形的左上点的横坐标
# 其他的类似
xx1 = np.maximum(x1[0], x1[1])
yy1 = np.maximum(y1[0], y1[1])
xx2 = np.minimum(x2[0], x2[1])
yy2 = np.minimum(y2[0], y2[1])

w = np.maximum(0.0, xx2-xx1+1)
h = np.maximum(0.0, yy2-yy1+1)
inter = w * h  # 计算交叠部分的面积
overlaps = inter/(areas1 + areas1 - inter) # 计算IoU
```

### 旋转框IoU计算

思路：首先计算两个矩形的所有交点，然后将交点集合按照顺时针排序，固定一个结点作为所有三角形的顶点，依次计算每一个三角形的面积，最后求和即可得到交叠区域的面积。

![1589172860930](/img/目标检测知识点总结/RIoU.png)